{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from CNNmodel import ConvModel\n",
    "from generator import Generator\n",
    "from utils import CustomDataSet, supervised_samples, load_data, print_config, ceil\n",
    "\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_SEED :   110404\n",
      "DATA_DIR    :   ./data\n",
      "USED_DATA   :  CIFAR10\n",
      "LEAKY       :    False\n",
      "NOSIE       :    False\n",
      "NUM_LABELLED:    50000\n",
      "DEVICE      :   cuda:0\n",
      "EPOCHS      :      100\n",
      "BATCH_SIZE  :       32\n"
     ]
    }
   ],
   "source": [
    "print_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.RANDOM_SEED)\n",
    "np.random.seed(config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, y_train, X_test, y_test, classes \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/ML/Project/learn/GAN/utils.py:56\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     53\u001b[0m \tX_test \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mUSED_DATA \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR10\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m \tdata \u001b[38;5;241m=\u001b[39m \u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \tX_train \u001b[38;5;241m=\u001b[39m Tensor(data\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[1;32m     58\u001b[0m \tX_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GAN/lib/python3.9/site-packages/torchvision/datasets/cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GAN/lib/python3.9/site-packages/torchvision/datasets/cifar.py:136\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GAN/lib/python3.9/site-packages/torchvision/datasets/cifar.py:131\u001b[0m, in \u001b[0;36mCIFAR10._check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, md5 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_list \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_list:\n\u001b[1;32m    130\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_folder, filename)\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GAN/lib/python3.9/site-packages/torchvision/datasets/utils.py:70\u001b[0m, in \u001b[0;36mcheck_integrity\u001b[0;34m(fpath, md5)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m md5 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_md5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GAN/lib/python3.9/site-packages/torchvision/datasets/utils.py:62\u001b[0m, in \u001b[0;36mcheck_md5\u001b[0;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_md5\u001b[39m(fpath: \u001b[38;5;28mstr\u001b[39m, md5: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m md5 \u001b[38;5;241m==\u001b[39m \u001b[43mcalculate_md5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GAN/lib/python3.9/site-packages/torchvision/datasets/utils.py:57\u001b[0m, in \u001b[0;36mcalculate_md5\u001b[0;34m(fpath, chunk_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(chunk_size):\n\u001b[0;32m---> 57\u001b[0m         \u001b[43mmd5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m md5\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, classes = load_data(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = X_train.shape[1]\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sup, y_sup = supervised_samples(X_train, y_train, config.NUM_LABELLED, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\tdef __init__(self, CNNlayer: nn.Module, num_classes) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.CNN = CNNlayer\n",
    "\n",
    "\t\tself.out = nn.Sequential(\n",
    "\t\t\tnn.Linear(512, num_classes),\n",
    "\t\t\tnn.Softmax(1)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.optimizer = optim.Adam(self.parameters(), lr = 0.0002, betas= [0.5, 0.999])\n",
    "\n",
    "\t\tself.criterion = nn.BCELoss()\n",
    "\t\n",
    "\t\n",
    "\tdef forward(self, X: Tensor):\n",
    "\t\tX = self.CNN(X)\n",
    "\t\tX = self.out(X)\n",
    "\n",
    "\t\treturn X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\tdef __init__(self, CNNlayer) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.CNN = CNNlayer\n",
    "\n",
    "\t\tself.out = nn.Sequential(\n",
    "\t\t\tnn.Linear(512, 1),\n",
    "\t\t\tnn.Sigmoid()\n",
    "\t\t)\n",
    "\t\n",
    "\t\tself.optimizer = optim.Adam(self.parameters(), lr=0.0002, betas=[0.5, 0.999])\n",
    "\t\tself.criterion = nn.BCELoss()\n",
    "\n",
    "\tdef forward(self, X: Tensor):\n",
    "\t\tX = self.CNN(X)\n",
    "\n",
    "\t\tX = self.out(X)\n",
    "\n",
    "\t\treturn X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleGAN(nn.Module):\n",
    "\tdef __init__(self, image_size, num_classes, CNNlayer: nn.Module, latent_size = 100, lr=0.0002):\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.latent_size = latent_size\n",
    "\n",
    "\t\tself.n_classes = num_classes\n",
    "\n",
    "\t\tself.CNN = CNNlayer\n",
    "\n",
    "\t\tself.generator = Generator(latent_size, image_size)\n",
    "\n",
    "\t\tself.classify = Classifier(CNNlayer, num_classes)\n",
    "\t\tself.discriminator = Discriminator(CNNlayer)\n",
    "\n",
    "\t\tself.name = \"TripleGAN\"\n",
    "\n",
    "\t\tself.history = {}\n",
    "\n",
    "\tdef forward(self, X: Tensor):\n",
    "\t\treturn self.classify(X)\n",
    "\t\n",
    "\tdef save(self, PATH = \"./\"):\n",
    "\t\ttorch.save(self.state_dict(), PATH)\n",
    "\n",
    "\tdef load(self, PATH):\n",
    "\t\tself.load_state_dict(torch.load(PATH))\n",
    "\t\n",
    "\tdef validation(self, X: Tensor, y: Tensor):\n",
    "\t\tself.classify.eval()\n",
    "\n",
    "\t\tnum_data = y.shape[0]\n",
    "\n",
    "\t\trun_size = 10000\n",
    "\n",
    "\t\tcurrent = 0\n",
    "\t\tcorrect = 0\n",
    "\t\t\n",
    "\t\twhile current < num_data:\n",
    "\t\t\tcorrect += torch.count_nonzero(torch.argmax(self.classify(X[current: current + run_size]), 1) == torch.argmax(y[current: current + run_size], 1))\n",
    "\t\t\tcurrent += run_size\n",
    "\n",
    "\t\treturn (float(correct.item()) / float(num_data))\n",
    "\t\n",
    "\tdef plot(self):\n",
    "\t\tif len(self.history) == 0:\n",
    "\t\t\treturn\n",
    "\t\tn = self.history['epochs']\n",
    "\n",
    "\t\tx = np.arange(n)\n",
    "\n",
    "\t\tfor name, value in self.history.items():\n",
    "\t\t\tif name == 'epochs':\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tplt.plot(x, value, label = name)\n",
    "\n",
    "\t\t\n",
    "\t\tplt.xlabel('epoch')\n",
    "\t\tplt.ylabel('acc')\n",
    "\n",
    "\t\tplt.legend()\n",
    "\t\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "\tdef training_step(self, model: nn.Module, optimizer: optim.Optimizer, criterion: nn.modules.loss._Loss, X: Tensor, y: Tensor):\n",
    "\t\tout: Tensor = model(X)\n",
    "\n",
    "\t\tloss: Tensor = criterion(out, y)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\treturn loss.item()\n",
    "\t\n",
    "\n",
    "\tdef fit(self, X: Tensor, y: Tensor, X_sup, y_sup, epochs = 100, batch_size = 64, save_best = True, PATH = \"./\", validation_data: list[torch.Tensor] = None):\n",
    "\t\tself.history['epochs'] = epochs\n",
    "\t\tself.history['train'] = []\n",
    "\n",
    "\t\tif validation_data:\n",
    "\t\t\tX_val, y_val = validation_data\n",
    "\t\t\tself.history['validation'] = []\n",
    "\n",
    "\t\tdatasets = CustomDataSet(X, y)\n",
    "\n",
    "\t\tnum_data = len(datasets)\n",
    "\n",
    "\t\tsup_datasets = CustomDataSet(X_sup, y_sup)\n",
    "\n",
    "\t\tdataloader = DataLoader(datasets, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\t\tsup_dataloader = DataLoader(sup_datasets, batch_size=batch_size//2, shuffle=True)\n",
    "\n",
    "\t\tdataloader.batch_size\n",
    "\n",
    "\t\tbest_acc = 0\n",
    "\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tself.classify.train()\n",
    "\t\t\tself.discriminator.train()\n",
    "\t\t\tself.generator.train()\n",
    "\n",
    "\t\t\tprint(f\"epoch: {epoch}\\nclassify: \")\n",
    "\t\t\t\n",
    "\t\t\t# for classify\n",
    "\t\t\tsup_loss = 0\n",
    "\t\t\tfor inputs, labels in tqdm(sup_dataloader):\n",
    "\t\t\t\tsup_loss += self.training_step(self.classify, self.classify.optimizer, self.classify.criterion, inputs.to(config.DEVICE), labels.to(config.DEVICE))\n",
    "\n",
    "\t\t\t\n",
    "\t\t\tsup_loss /= ceil(num_data/(batch_size//2))\n",
    "\n",
    "\t\t\tprint(f'GAN:')\n",
    "\t\t\t# for discriminator and generator\n",
    "\t\t\treal_loss = 0\n",
    "\t\t\tfake_loss = 0\n",
    "\t\t\tgen_loss = 0\n",
    "\t\t\tfor inputs, _ in tqdm(dataloader):\n",
    "\t\t\t\treal_loss += self.training_step(self.discriminator, self.discriminator.optimizer, self.discriminator.criterion, inputs, torch.ones((inputs.shape[0], 1)).to(config.DEVICE))\n",
    "\t\t\t\tz = torch.randn((inputs.shape[0], self.latent_size)).to(config.DEVICE)\n",
    "\t\t\t\t\n",
    "\t\t\t\tgen_out = self.generator(z)\n",
    "\t\t\t\tfake_loss += self.training_step(self.discriminator, self.discriminator.optimizer, self.discriminator.criterion, gen_out, torch.zeros(inputs.shape[0], 1).to(config.DEVICE))\n",
    "\n",
    "\t\t\t\tgen_out = self.generator(z)\n",
    "\t\t\t\tgen_loss += self.training_step(self.discriminator, self.generator.optimizer, self.discriminator.criterion, gen_out, torch.ones((inputs.shape[0], 1)).to(config.DEVICE))\n",
    "\n",
    "\t\t\treal_loss /= ceil(num_data/batch_size)\n",
    "\t\t\tfake_loss /= ceil(num_data/batch_size)\n",
    "\t\t\tgen_loss /= ceil(num_data/batch_size)\n",
    "\n",
    "\t\t\ttrain_acc = self.validation(X_sup, y_sup)\n",
    "\n",
    "\t\t\tself.history['train'].append(train_acc)\n",
    "\n",
    "\t\t\tprint(f\"train acc: {train_acc*100:.2f}%\", end = \"\")\n",
    "\n",
    "\t\t\tif validation_data:\n",
    "\t\t\t\tval_acc = self.validation(X_val, y_val)\n",
    "\n",
    "\t\t\t\tself.history['validation'].append(val_acc)\n",
    "\n",
    "\t\t\t\tprint(f', val acc: {val_acc*100:.2f}%', end = \"\")\n",
    "\n",
    "\t\t\t\tif val_acc >= best_acc:\n",
    "\t\t\t\t\tbest_acc = val_acc\n",
    "\n",
    "\t\t\t\t\tif save_best:\n",
    "\t\t\t\t\t\tself.save(PATH + self.name + \".pt\")\n",
    "\t\t\t\n",
    "\t\t\tprint(f\", classification_loss: {sup_loss:.2f}, discrimination_loss: {(real_loss+fake_loss)/2:.2f}, generation_loss: {gen_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TripleGAN(X_train.shape[1:], n_classes, ConvModel(channel, config.LEAKY)).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "classify: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 84.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:12<00:00, 61.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 13.10%, val acc: 13.31%, classification_loss: 0.01, discrimination_loss: 0.60, generation_loss: 0.98\n",
      "epoch: 1\n",
      "classify: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 439.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:12<00:00, 61.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 16.80%, val acc: 15.60%, classification_loss: 0.01, discrimination_loss: 0.59, generation_loss: 1.00\n",
      "epoch: 2\n",
      "classify: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 446.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 50/782 [00:00<00:12, 59.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_sup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUSED_DATA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 129\u001b[0m, in \u001b[0;36mTripleGAN.fit\u001b[0;34m(self, X, y, X_sup, y_sup, epochs, batch_size, save_best, PATH, validation_data)\u001b[0m\n\u001b[1;32m    126\u001b[0m \tfake_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mcriterion, gen_out, torch\u001b[38;5;241m.\u001b[39mzeros(inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mDEVICE))\n\u001b[1;32m    128\u001b[0m \tgen_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator(z)\n\u001b[0;32m--> 129\u001b[0m \tgen_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m real_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m ceil(num_data\u001b[38;5;241m/\u001b[39mbatch_size)\n\u001b[1;32m    132\u001b[0m fake_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m ceil(num_data\u001b[38;5;241m/\u001b[39mbatch_size)\n",
      "Cell \u001b[0;32mIn[31], line 73\u001b[0m, in \u001b[0;36mTripleGAN.training_step\u001b[0;34m(self, model, optimizer, criterion, X, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m loss: Tensor \u001b[38;5;241m=\u001b[39m criterion(out, y)\n\u001b[1;32m     72\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 73\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/GAN/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GAN/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, X_sup, y_sup, epochs=config.EPOCHS, batch_size=config.BATCH_SIZE, PATH=config.USED_DATA + \"/\", validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(config.USED_DATA + \"/TripleGAN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3404"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.validation(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
