{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from utils import *\n",
    "import config\n",
    "import random\n",
    "\n",
    "from typing import Type\n",
    "\n",
    "from Classify import Classifier\n",
    "from Network_model import Generator, ConvModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "import copy \n",
    "\n",
    "from Network_model import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_SEED   :  11042004\n",
      "DATA_DIR      :    ./data\n",
      "USED_DATA     :     MNIST\n",
      "NUM_LABELLED  :       100\n",
      "DEVICE        :    cuda:0\n",
      "EPOCHS        :        10\n",
      "BATCH_SIZE    :       128\n",
      "LEARNING_RATE :    0.0004\n",
      "SCHED         :     False\n",
      "GAN_BATCH_SIZE:       128\n"
     ]
    }
   ],
   "source": [
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seeds ...... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(config.RANDOM_SEED)\n",
    "random.seed(config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"MarginGAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.USED_DATA == \"CIFAR10\":\n",
    "\tmean = [0.5]*3\n",
    "\tstd = [0.5]*3\n",
    "\n",
    "\ttrain_tfm = tt.Compose([\n",
    "\t\ttt.RandomCrop(32, padding=4, padding_mode='edge'),\n",
    "\t\ttt.RandomHorizontalFlip(),\n",
    "\t\ttt.Normalize(mean, std, inplace=True)\n",
    "\t])\n",
    "\n",
    "if config.USED_DATA == \"MNIST\":\n",
    "\tmean = [0.5]\n",
    "\tstd = [0.5]\n",
    "\ttrain_tfm = tt.Compose([\n",
    "\t\ttt.Resize(32),\n",
    "\t\ttt.Normalize(mean, std, inplace=True)\n",
    "\t])\n",
    "\n",
    "test_tfm = tt.Compose([\n",
    "\ttt.Resize(32),\n",
    "\ttt.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds, classes = load_data(train_tfm, test_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = train_ds.x\n",
    "y_full = train_ds.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(classes)\n",
    "channels = train_ds[0][0].shape[0] # MNIST\n",
    "n_classes, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sup, y_sup, X_unsup, _ = supervised_samples(X_full, y_full, config.NUM_LABELLED, n_classes, get_unsup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = CreateDataLoader(test_ds, batch_size=512, transform=test_tfm, device=config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.Conv = ConvModel(in_channels)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.out = nn.Linear(512, n_classes)\n",
    "        \n",
    "    def forward(self, X: Tensor):\n",
    "        out = self.Conv(X)\n",
    "        out = self.dropout(out)\n",
    "        out = self.out(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginGAN: \n",
    "    def __init__(self, latent_size, n_channels, n_classes, device): \n",
    "        self.latent_size = latent_size\n",
    "        self.n_classes = n_classes\n",
    "        self.generator = Generator(latent_size, n_channels)\n",
    "        self.discriminator = Discriminator(n_channels, 1) \n",
    "        self.classifier = Classifier(n_channels, n_classes)\n",
    "\n",
    "        self.CEloss = nn.CrossEntropyLoss() \n",
    "        self.BCEloss = nn.BCELoss()\n",
    "        self.device = device \n",
    "        self.to(device)\n",
    "    \n",
    "    def to(self, device): \n",
    "        self.generator.to(device) \n",
    "        self.discriminator.to(device)\n",
    "        self.classifier.to(device)\n",
    "    \n",
    "    def load_gen_state_dict(self, file):\n",
    "        self.generator.load_state_dict(torch.load(file))\n",
    "    \n",
    "    def accuracy(self, test_dl): \n",
    "        corrected = 0\n",
    "        for b in tqdm(test_dl):\n",
    "            images, y = b\n",
    "            outs = self.classifier.forward(images)\n",
    "            outs = torch.argmax(outs[:, :-1], dim=1)\n",
    "            corrected += (outs == y).sum().item()\n",
    "        return corrected / test_dl.num_data()\n",
    "    \n",
    "    def discriminator_step(self, real_imgs:torch.Tensor, batch_size): \n",
    "        # Train discriminator to recognize real imgs as real imgs\n",
    "        real_batch_size = real_imgs.shape[0]\n",
    "        outs = self.discriminator(real_imgs)\n",
    "        outs = F.softmax(outs, dim = 1)[:, 0]\n",
    "        # outs is probability of discriminator predict fake images\n",
    "        # because this is real images, we want this {outs} to be minimize\n",
    "        y_hat = torch.zeros([real_batch_size], device = self.device) \n",
    "        real_loss = self.BCEloss(outs, y_hat)\n",
    "\n",
    "        # Train discriminator to recognize fake imgs as fake imgs \n",
    "        z = torch.randn([batch_size, self.latent_size, 1, 1], device = self.device)\n",
    "        fake_imgs = self.generator(z)\n",
    "        fake_outs = self.discriminator(fake_imgs)\n",
    "        fake_outs = F.softmax(fake_outs, dim = 1)[:, 1]\n",
    "        # outs is probability of discriminator predict fake images\n",
    "        # because this is fake images, we want this {outs} to be maximize\n",
    "        fake_y_hat = torch.ones([batch_size], device = self.device) \n",
    "        fake_loss = self.BCEloss(fake_outs, fake_y_hat)\n",
    "        return real_loss + fake_loss\n",
    "    \n",
    "    def classifier_step(self, sup_imgs, sup_labels, unsup_imgs, batch_size): \n",
    "        # Loss for labeled samples\n",
    "        sup_outs = self.classifier(sup_imgs) \n",
    "        sup_loss = self.CEloss(sup_outs, sup_labels)\n",
    "\n",
    "        # Loss for unlabeled samples\n",
    "        # Pseudo_label:  Pick up the class which\n",
    "        # has maximum predicted probability for each unlabeled\n",
    "        # sample\n",
    "        unsup_outs = self.classifier(unsup_imgs) \n",
    "        unsup_pseudolabels = torch.argmax(unsup_outs, dim = 1) \n",
    "        # print(unsup_pseudolabels.shape)\n",
    "        unsup_loss = self.CEloss(unsup_outs, unsup_pseudolabels)\n",
    "\n",
    "        # Loss for generated samples. Also pseudo_labelling as for \n",
    "        # unsup imgs, but now apply the inverted binary cross entropy \n",
    "        # as loss. Aim: decrease the margin of these data points\n",
    "        # and make the prediction distribution flat\n",
    "        z = torch.randn([batch_size, self.latent_size, 1, 1], device = self.device)\n",
    "        fake_imgs = self.generator(z) \n",
    "        fake_outs = self.classifier(fake_imgs)\n",
    "        fake_pseudolabels = torch.argmin(fake_outs, dim = 1) \n",
    "        fake_loss = self.CEloss(fake_outs, fake_pseudolabels) \n",
    "\n",
    "        return sup_loss + unsup_loss + fake_loss\n",
    "\n",
    "    def fit(self, epochs, batch_size, batch_per_epoch, dis_lr, max_lr, sup_ds:CustomDataSet, unsup_ds:CustomDataSet, full_ds:CustomDataSet, test_dl, optim:Type[optim.Optimizer], weight_decay = 0, sched = True, PATH = \".\", save_best = False, grad_clip = False): \n",
    "        optimizerD = optim(self.discriminator.parameters(), lr = dis_lr)\n",
    "        optimizerC = optim(self.classifier.parameters(), lr = max_lr, weight_decay = weight_decay)\n",
    "\n",
    "        if sched: \n",
    "            OneCycleLR = torch.optim.lr_scheduler.OneCycleLR(optimizerC, max_lr, epochs=epochs, steps_per_epoch=batch_per_epoch)\n",
    "\n",
    "        self.discriminator.train()\n",
    "        self.classifier.train() \n",
    "        for epoch in (range(epochs)):\n",
    "            for i in range(batch_per_epoch): \n",
    "                sup_imgs, labels = random_split(sup_ds, [batch_size, len(sup_ds) - batch_size])[0][:]\n",
    "                full_imgs = random_split(full_ds, [batch_size, len(full_ds) - batch_size])[0][:]\n",
    "                unsup_imgs = random_split(unsup_ds, [batch_size, len(unsup_ds) - batch_size])[0][:]\n",
    "                # train discriminator\n",
    "                if (i%2 == 1):\n",
    "                    D_loss = self.discriminator_step(full_imgs.to(self.device), batch_size)\n",
    "                    D_loss.backward()\n",
    "                    optimizerD.step()\n",
    "                    tqdm.write(f'D_loss: {D_loss.detach().item()}', end = \"\\r\")\n",
    "                # train classifier\n",
    "                C_loss = self.classifier_step(sup_imgs.to(self.device), labels.to(self.device), unsup_imgs.to(self.device), batch_size) \n",
    "                C_loss.backward()\n",
    "                \n",
    "                if grad_clip: \n",
    "                    torch.nn.utils.clip_grad_value_(self.classifier.parameters(), 0.1)\n",
    "                \n",
    "                optimizerC.step()\n",
    "                optimizerC.zero_grad()\n",
    "                if sched: \n",
    "                    OneCycleLR.step()\n",
    "                \n",
    "                tqdm.write(f'C_loss: {C_loss.detach().item()}', end = \"\\r\")\n",
    "                \n",
    "            self.discriminator.eval() \n",
    "            self.classifier.eval()\n",
    "            tqdm.write(f'accuracy: {self.accuracy(test_dl)}', end = \"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mGAN = MarginGAN(100, channels, n_classes, config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (Conv): ConvModel(\n",
       "    (initial): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (Conv): Sequential(\n",
       "      (0): ConvBn(\n",
       "        (Conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (Bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): ConvBn(\n",
       "        (Conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (Bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): ConvBn(\n",
       "        (Conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (Bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (pool): Identity()\n",
       "      )\n",
       "    )\n",
       "    (adaptivePool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mGAN.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "mGAN.load_gen_state_dict(f\"DCGAN/{config.USED_DATA}/netG_epoch_00{i}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_ds = CustomDataSet(X_sup, y_sup, train_tfm)\n",
    "full_ds = CustomDataSet(X_full, None, train_tfm)\n",
    "unsup_ds = CustomDataSet(X_unsup, None, train_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 5.4620990753173837821\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.65606307983398440997\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.6090240478515625e-12\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.5120520591735845e-18\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.4998936653137207e-24\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.4353010654449463-293\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.4172558784484863-301\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.3798391819000244-453\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.35726571083068854323\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_loss: 2.3383316993713386\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7381\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mGAN.fit(10, 64, 50, 1e-5, 2*1e-4, sup_ds, unsup_ds, full_ds, test_dl, optim.RMSprop, grad_clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.52it/s]\n"
     ]
    }
   ],
   "source": [
    "corrected = 0\n",
    "for b in tqdm(test_dl):\n",
    "    images, y = b\n",
    "    outs = mGAN.classifier.forward(images)\n",
    "    outs = torch.argmax(outs, dim=1)\n",
    "    corrected += (outs == y).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 0.815\n"
     ]
    }
   ],
   "source": [
    "print(f\"{i}: {corrected / test_dl.num_data()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstonePrjML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
