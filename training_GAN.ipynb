{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import set_random_seed, load_data, CreateDataLoader\n",
    "\n",
    "from Generator import Generator\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seeds ...... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DCGAN/EMNIST'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = f'GAN/{config.USED_DATA}'\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.USED_DATA == \"CIFAR10\":\n",
    "\ttransform = transforms.Compose([\n",
    "\t\t\t\t\t\t\t   transforms.Resize(64),\n",
    "\t\t\t\t\t\t\t   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "\t\t\t\t\t\t   ])\n",
    "\tn_channels = 3\n",
    "else:\n",
    "# elif config.USED_DATA == \"MNIST\" or config.USED_DATA == \"DOODLE\":\n",
    "\ttransform = transforms.Compose([\n",
    "\t\t\t\t\t\t\t   transforms.Resize(64),\n",
    "\t\t\t\t\t\t\t   transforms.Normalize([0.5], [0.5]),\n",
    "\t\t\t\t\t\t   ])\n",
    "\tn_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.CustomDataSet at 0x7fd26433d8b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, *_ = load_data(transform)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = CreateDataLoader(dataset, batch_size = config.GAN_BATCH_SIZE, device = config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "\tclassname = m.__class__.__name__\n",
    "\tif classname.find('Conv') != -1:\n",
    "\t\tm.weight.data.normal_(0.0, 0.02)\n",
    "\telif classname.find('BatchNorm') != -1:\n",
    "\t\tm.weight.data.normal_(1.0, 0.02)\n",
    "\t\tm.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (initial): TransposeBN(\n",
       "    (deConv): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (Bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (Transposed): Sequential(\n",
       "    (0): TransposeBN(\n",
       "      (deConv): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (Bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): TransposeBN(\n",
       "      (deConv): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (Bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): TransposeBN(\n",
       "      (deConv): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (Bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (out): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = Generator(latent_size, n_channels).to(config.DEVICE)\n",
    "netG.apply(weights_init)\n",
    "netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\tdef __init__(self, n_channels, filters = [64, 128, 256, 512]):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "\t\tself.main = nn.Sequential(\n",
    "\t\t\t# input is (nc) x 64 x 64\n",
    "\t\t\tnn.Conv2d(n_channels, filters[0], 4, 2, 1, bias=False),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\t\t\t# state size. (ndf) x 32 x 32\n",
    "\t\t\tnn.Conv2d(filters[0], filters[1], 4, 2, 1, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(filters[1]),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\t\t\t# state size. (ndf*2) x 16 x 16\n",
    "\t\t\tnn.Conv2d(filters[1], filters[2], 4, 2, 1, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(filters[2]),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\t\t\t# state size. (ndf*4) x 8 x 8\n",
    "\t\t\tnn.Conv2d(filters[2], filters[3], 4, 2, 1, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(filters[3]),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\t\t\t# state size. (ndf*8) x 4 x 4\n",
    "\t\t\tnn.Conv2d(filters[3], 1, 4, 1, 0, bias=False)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, X: Tensor):\n",
    "\t\tout = self.main(X)\n",
    "\n",
    "\t\treturn out.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = Discriminator(n_channels).to(config.DEVICE)\n",
    "netD.apply(weights_init)\n",
    "netD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = [0.5, 0.999])\n",
    "# optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = [0.5, 0.999])\n",
    "\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr = 0.0001)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(64, latent_size, 1, 1, device=config.DEVICE)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9578e4a0f449319dc63669c3f83a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/9] Loss_D: 1.5992 Loss_G: 3.5196 D(x): 2.7548 D(G(z)): 1.1917 / -3.479240406\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a27a32fda341938fe5fe688afad31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/9] Loss_D: 0.4179 Loss_G: 2.0271 D(x): 1.0520 D(G(z)): -3.1438 / -1.83953\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b5e6fb4893455caa75468481374ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/9] Loss_D: 0.2953 Loss_G: 4.1093 D(x): 2.9906 D(G(z)): -1.6436 / -4.08906\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585d4b24650c420087789cde8efe90d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/9] Loss_D: 0.4049 Loss_G: 3.9412 D(x): 3.5740 D(G(z)): -1.2486 / -3.91381\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47911c9e4176476599f0a077c4aeca78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/9] Loss_D: 0.1903 Loss_G: 2.9022 D(x): 2.3728 D(G(z)): -3.0002 / -2.82425\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c992441759f9479b8c0d0748b50495fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/9] Loss_D: 0.0971 Loss_G: 5.7653 D(x): 4.6568 D(G(z)): -2.8054 / -5.761259\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ee0992239142caae7a6fd1459dd446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/9] Loss_D: 0.3841 Loss_G: 2.9023 D(x): 2.5558 D(G(z)): -1.5391 / -2.830386\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdd8190cadb4b8e8d0032ccc4d11663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/9] Loss_D: 0.0807 Loss_G: 4.0302 D(x): 3.6543 D(G(z)): -3.6660 / -4.004923\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feee25db1bfe4f0c9542e3aa83a33874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/9] Loss_D: 3.6716 Loss_G: 1.0425 D(x): -3.6118 D(G(z)): -6.6633 / -0.38039\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae1603b0aa74c85a7bfb07aa5022b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/9] Loss_D: 0.0611 Loss_G: 4.3702 D(x): 3.9215 D(G(z)): -4.0332 / -4.350262\r"
     ]
    }
   ],
   "source": [
    "niter = 10\n",
    "g_loss = []\n",
    "d_loss = []\n",
    "\n",
    "for epoch in range(niter):\n",
    "\tfor batch in tqdm(dataloader, leave = True, position=0):\n",
    "\t\timages, _ = batch\n",
    "\t\tbatch_size = images.size(0)\n",
    "\t\t############################\n",
    "\t\t# (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "\t\t###########################\n",
    "\t\t# train with real\n",
    "\t\tnetD.zero_grad()\n",
    "\t\tlabel = torch.full((batch_size,), real_label, device=config.DEVICE, dtype=torch.float)\n",
    "\n",
    "\t\toutput = netD(images)\n",
    "\t\terrD_real = criterion(output, label)\n",
    "\t\terrD_real.backward()\n",
    "\t\tD_x = output.mean().item()\n",
    "\n",
    "\t\t# train with fake\n",
    "\t\tnoise = torch.randn(batch_size, latent_size, 1, 1, device=config.DEVICE)\n",
    "\t\tfake = netG(noise)\n",
    "\t\tlabel.fill_(fake_label)\n",
    "\t\toutput = netD(fake.detach())\n",
    "\t\terrD_fake = criterion(output, label)\n",
    "\t\terrD_fake.backward()\n",
    "\t\tD_G_z1 = output.mean().item()\n",
    "\t\terrD = errD_real + errD_fake\n",
    "\t\toptimizerD.step()\n",
    "\n",
    "\t\t############################\n",
    "\t\t# (2) Update G network: maximize log(D(G(z)))\n",
    "\t\t###########################\n",
    "\t\tnetG.zero_grad()\n",
    "\t\tlabel.fill_(real_label)  # fake labels are real for generator cost\n",
    "\t\toutput = netD(fake)\n",
    "\t\terrG = criterion(output, label)\n",
    "\t\terrG.backward()\n",
    "\t\tD_G_z2 = output.mean().item()\n",
    "\t\toptimizerG.step()\n",
    "\n",
    "\t\ts = '[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % (epoch, niter-1, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)\n",
    "\t\t\n",
    "\t\ttqdm.write(s, end = \"\\r\")\n",
    "\t\t\n",
    "\tfake = netG(fixed_noise)\n",
    "\tvutils.save_image(fake.detach(),f'{PATH}/fake_samples_epoch_{epoch:03d}.png', normalize=True)\n",
    "\t\t\n",
    "\t\n",
    "\t\n",
    "\t# Check pointing for every epoch\n",
    "\ttorch.save(netG.state_dict(), f'{PATH}/netG_epoch_{epoch:03d}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
