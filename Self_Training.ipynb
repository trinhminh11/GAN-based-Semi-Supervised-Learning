{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from utils import *\n",
    "import config\n",
    "import random\n",
    "\n",
    "from typing import Type\n",
    "\n",
    "from Classify import Classifier\n",
    "from Network_model import Generator, ConvModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "import copy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_SEED   :  11042004\n",
      "DATA_DIR      :    ./data\n",
      "USED_DATA     :     MNIST\n",
      "NUM_LABELLED  :       100\n",
      "DEVICE        :    cuda:0\n",
      "EPOCHS        :        10\n",
      "BATCH_SIZE    :       128\n",
      "LEARNING_RATE :    0.0004\n",
      "SCHED         :     False\n",
      "GAN_BATCH_SIZE:       128\n"
     ]
    }
   ],
   "source": [
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seeds ...... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(config.RANDOM_SEED)\n",
    "random.seed(config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"GANSSL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MNIST/GANSSL/_100'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = get_PATH(name)\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.USED_DATA == \"CIFAR10\":\n",
    "\tmean = [0.5]*3\n",
    "\tstd = [0.5]*3\n",
    "\n",
    "\ttrain_tfm = tt.Compose([\n",
    "\t\ttt.RandomCrop(32, padding=4, padding_mode='edge'),\n",
    "\t\ttt.RandomHorizontalFlip(),\n",
    "\t\ttt.Normalize(mean, std, inplace=True)\n",
    "\t])\n",
    "\n",
    "if config.USED_DATA == \"MNIST\":\n",
    "\tmean = [0.5]\n",
    "\tstd = [0.5]\n",
    "\ttrain_tfm = tt.Compose([\n",
    "\t\t# tt.Resize(32),\n",
    "\t\ttt.Normalize(mean, std, inplace=True)\n",
    "\t])\n",
    "\n",
    "test_tfm = tt.Compose([\n",
    "\t# tt.Resize(32),\n",
    "\ttt.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds, classes = load_data(train_tfm, test_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = train_ds.x\n",
    "y_full = train_ds.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(classes)\n",
    "channels = train_ds[0][0].shape[0] # MNIST\n",
    "n_classes, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sup, y_sup, X_unsup, _ = supervised_samples(X_full, y_full, config.NUM_LABELLED, n_classes, get_unsup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.Conv = ConvModel(in_channels)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.out = nn.Linear(512, n_classes+1)\n",
    "        \n",
    "    def forward(self, X: Tensor):\n",
    "        out = self.Conv(X)\n",
    "        out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = CreateDataLoader(test_ds, batch_size=512, transform=test_tfm, device=config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred): \n",
    "     return torch.mean(y_true * y_pred, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, latent_size, n_channels, n_classes, device) -> None:\n",
    "        self.generator = Generator(latent_size, n_channels)\n",
    "        self.discriminator = Discriminator(n_channels, n_classes)\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.CEloss = nn.CrossEntropyLoss()\n",
    "        self.BCEloss = nn.BCELoss()\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.resize = tt.Resize(32)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.generator = self.generator.to(device)\n",
    "        self.discriminator = self.discriminator.to(device)\n",
    "    \n",
    "    def load_gen_state_dict(self, file):\n",
    "        self.generator.load_state_dict(torch.load(file))\n",
    "    \n",
    "    def classifier_step(self, X, y):\n",
    "        outs = self.discriminator(X)\n",
    "        # loss = wasserstein_loss(outs.to(torch.float), y.to(torch.float))\n",
    "        loss = self.CEloss(outs, y)\n",
    "        \n",
    "        # loss.backward()\n",
    "\n",
    "        # optim.step()\n",
    "        # tqdm.write(f'classifier_loss: {loss.detach().item()}', end = \"\\r\")\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def discriminator_real_step(self, X):\n",
    "        \n",
    "        batch_size = X.shape[0]\n",
    "        outs = self.discriminator(X)\n",
    "        outs = F.softmax(outs, dim=1)[:, -1]   # shape: B x 1\n",
    "        # outs is probability of discriminator predict fake images\n",
    "        # because this is real images, we want this {outs} to be minimize\n",
    "        \n",
    "        y_hat = torch.zeros([batch_size], device=self.device)\n",
    "\n",
    "        loss = self.BCEloss(outs, y_hat)\n",
    "        # loss.backward()\n",
    "\n",
    "        # optim.step()\n",
    "        # tqdm.write(f'disc_real_loss: {loss.detach().item()}', end = \"\\r\")\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "\n",
    "    \n",
    "    def discriminator_fake_step(self, batch_size):\n",
    "        z = torch.randn([batch_size, self.latent_size, 1, 1], device = self.device)\n",
    "        fake_images = self.generator(z)\n",
    "\n",
    "        fake_images = self.resize(fake_images)\n",
    "\n",
    "        outs = self.discriminator(fake_images)\n",
    "        y_hat = torch.full([batch_size], self.n_classes, device=self.device)\n",
    "\n",
    "        loss = self.CEloss(outs, y_hat)\n",
    "        # loss.backward()\n",
    "\n",
    "        # optim.step()\n",
    "        # tqdm.write(f'disc_fake_loss: {loss.detach().item()}', end = \"\\r\")\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def accuracy(self, test_dl): \n",
    "        corrected = 0\n",
    "        for b in tqdm(test_dl):\n",
    "            images, y = b\n",
    "            outs = self.discriminator.forward(images)\n",
    "            outs = torch.argmax(outs[:, :-1], dim=1)\n",
    "            corrected += (outs == y).sum().item()\n",
    "        return corrected / test_dl.num_data()\n",
    "                \n",
    "    def fit(self, epochs, batch_size, batch_per_epoch, dis_lr, sup_ds: CustomDataSet, full_ds: CustomDataSet, optim: Type[optim.Optimizer], PATH = \".\", save_best = False, grad_clip = True):\n",
    "        optimizerD = optim(self.discriminator.parameters(), lr = dis_lr)\n",
    "        n_sup = len(sup_ds) \n",
    "        n_data = len(full_ds)\n",
    "\n",
    "\n",
    "        for epoch in (range(epochs)):\n",
    "            print(f\"epoch: {epoch}\")\n",
    "            self.discriminator.train()\n",
    "            with open('acc.txt', 'w') as F: \n",
    "                for i in (range(batch_per_epoch)):\n",
    "                    sup_images, labels = random_split(sup_ds, [batch_size, n_sup - batch_size])[0][:]\n",
    "                    C_loss = self.classifier_step(sup_images.to(self.device), labels.to(self.device))\n",
    "                    full_images = random_split(full_ds, [batch_size, n_data-batch_size])[0][:]\n",
    "                \n",
    "                    loss_real = self.discriminator_real_step(full_images.to(self.device))\n",
    "                    loss_fake = self.discriminator_fake_step(batch_size)\n",
    "                    D_loss = (loss_real + loss_fake)/2\n",
    "                    \n",
    "\n",
    "                    loss = C_loss+ D_loss/2\n",
    "\n",
    "                    loss.backward()\n",
    "                    if grad_clip: \n",
    "                        nn.utils.clip_grad_value_(self.discriminator.parameters(), 0.1)\n",
    "\n",
    "                    optimizerD.step()\n",
    "                    tqdm.write(f'loss: {loss.detach().item()}', end = \"\\r\")\n",
    "                \n",
    "                self.discriminator.eval()\n",
    "                # F.write(f\"\\n accuracy: {self.accuracy(test_dl)}\")\n",
    "                tqdm.write(f'accuracy: {self.accuracy(test_dl)}', end = \"\\r\")\n",
    "                    # self.classifier_step(sup_images, labels, optimizerD)\n",
    "                    # self.discriminator_real_step(full_images, optimizerD)\n",
    "                    # self.discriminator_fake_step(_full_batch_size, optimizerD)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GANSSL = GAN(100, channels, 10, config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GANSSL.load_gen_state_dict(f\"DCGAN/{config.USED_DATA}/netG_epoch_024.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_ds = CustomDataSet(X_sup, y_sup, train_tfm)\n",
    "full_ds = CustomDataSet(X_full, None, train_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GANSSL.fit(config.EPOCHS, 64, 50, 1e-5, sup_ds, full_ds, optim.RMSprop, grad_clip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.98it/s]\n"
     ]
    }
   ],
   "source": [
    "corrected = 0\n",
    "for b in tqdm(test_dl):\n",
    "    images, y = b\n",
    "    outs = GANSSL.discriminator.forward(images)\n",
    "    outs = torch.argmax(outs[:, :-1], dim=1)\n",
    "    corrected += (outs == y).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7086"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected / test_dl.num_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfTraining: \n",
    "    def __init__(self, model: GAN, X_sup: Tensor, y_sup: Tensor, X: Tensor, X_unsup: Tensor, test_dl: DeviceDataLoader, transform, num_rounds): \n",
    "        '''\n",
    "            Input of self-training model:\n",
    "            model: classifier\n",
    "            num_rounds: number of self_training rounds\n",
    "            sup_samples: number of supervised samples\n",
    "        '''\n",
    "        self.model = model \n",
    "        self.X_sup = X_sup\n",
    "        self.y_sup = y_sup\n",
    "        self.X = X\n",
    "        self.X_unsup = X_unsup\n",
    "        self.transform = transform\n",
    "        self.test_dataloader = test_dl\n",
    "        \n",
    "        self.num_rounds = num_rounds\n",
    "    \n",
    "\n",
    "    def CalDisagreement(self, h1: GAN, h2: GAN, dataset: CustomDataSet): \n",
    "        '''\n",
    "            Calculate disagreement between teacher model and student model\n",
    "            h1: Teacher model \n",
    "            h2: Student model\n",
    "        '''\n",
    "        disagreement = 0\n",
    "        for x, _ in dataset: \n",
    "            disagreement += (torch.argmax(h1.discriminator(x.unsqueeze(0))) == torch.argmax(h2.discriminator(x.unsqueeze(0))))\n",
    "        \n",
    "        return disagreement/len(dataset)\n",
    "\n",
    "    def random_sampling(self, sample_fraction: float, dataset: CustomDataSet, n: int): \n",
    "        dataset_set: list[CustomDataSet] = []\n",
    "        for _ in range(n): \n",
    "            \n",
    "            idx = random.sample(range(0, len(dataset)), int(len(dataset)*sample_fraction))\n",
    "            data_X = dataset.x[idx]\n",
    "            data_y = dataset.y[idx]\n",
    "\n",
    "            dataset_set.append(CustomDataSet(data_X, data_y))\n",
    "        return dataset_set\n",
    "    \n",
    "    def random_sampling(self, idx, sample_fraction, n):\n",
    "        subsets_idx = []\n",
    "        for _ in range(n):\n",
    "            subset_idx = random.sample(idx, int(len(idx) * sample_fraction))\n",
    "            subsets_idx.append(subset_idx)\n",
    "        \n",
    "        return subsets_idx\n",
    "\n",
    "    def selfTraining(self, epochs, lr, batch_size: int, batch_per_epoch,  sample_fraction: float, n: int, opt_func: Type[optim.Optimizer] = optim.Adam, sched = True, PATH = \".\", save_best = False, device = 'cpu'): \n",
    "        teacher_model = copy.deepcopy(self.model)\n",
    "        full_ds = CustomDataSet(self.X, None)\n",
    "        \n",
    "        for _ in range(self.num_rounds): \n",
    "            sup_ds = CustomDataSet(self.X_sup, self.y_sup)\n",
    "            \n",
    "            student_model = copy.deepcopy(teacher_model) \n",
    "            student_model.fit(epochs, batch_size, batch_per_epoch, lr, sup_ds, full_ds, opt_func)\n",
    "\n",
    "            print(\"start\")\n",
    "           \n",
    "            unsup_ds = CustomDataSet(self.X_unsup, None, self.transform)\n",
    "            unsup_dl = CreateDataLoader(unsup_ds, batch_size=1, device = device)\n",
    "            confidence = Tensor()\n",
    "            for unsup_imgs in tqdm(unsup_dl):\n",
    "            # for i in tqdm(range(0, len(unsup_ds), batch_size)):  \n",
    "                # unsup_img = unsup_ds[i:min(len(unsup_ds), i+batch_size)]\n",
    "                prob = F.softmax(student_model.discriminator(unsup_imgs).cpu()[:, :-1], dim=1)\n",
    "                # add 0.1 into label in order to prevent collapsing at label 0\n",
    "                labels = Tensor([0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 5.1, 7.1, 8.1, 9.1])\n",
    "                a = torch.matmul(prob, labels)\n",
    "                confidence = torch.cat((confidence, a))\n",
    "            \n",
    "            print(confidence.shape)\n",
    "            print(\"threshold\")\n",
    "            break\n",
    "            threshold = np.median(np.array(list(d.values())))\n",
    "            threshold_idx = []\n",
    "\n",
    "            for i in range(len(d)):\n",
    "                if d[i] > threshold:\n",
    "                    threshold_idx.append(i)\n",
    "            \n",
    "            print(\"sampling\")\n",
    "            # randomly sample sample_fraction of threshold_ds\n",
    "            dataset_idx = self.random_sampling(threshold_idx, sample_fraction=sample_fraction, n=n)\n",
    "\n",
    "            max = 0\n",
    "\n",
    "            # for subset_idx in dataset_idx:\n",
    "            #     print(':)')\n",
    "            #     model = model = Classifier(channels, n_classes).to(config.DEVICE)\n",
    "            #     model.train()\n",
    "            #     # calculate U\\U[i]\n",
    "            #     unlabel = self.X_unsup\n",
    "            #     unlabel_i = self.X_unsup[subset_idx]\n",
    "\n",
    "            #     counterpart_idx = []\n",
    "\n",
    "            #     for i in range(len(self.X_unsup)):\n",
    "            #         if i not in subset_idx:\n",
    "            #             counterpart_idx.append(i)\n",
    "                \n",
    "            #     counterpart = self.X_unsup[counterpart_idx]\n",
    "\n",
    "            #     y_counterpart = torch.argmax(teacher_model(counterpart), dim=1)  # shape: len(counterpart) x 1\n",
    "                \n",
    "            #     print(y_counterpart)\n",
    "            # break\n",
    "            # '''\n",
    "            for I in range(len(dataset_idx)): \n",
    "                model = Classifier(channels, n_classes).to(config.DEVICE)\n",
    "                model.train()\n",
    "                # calculate U\\U[i]\n",
    "                unlabel = self.X_unsup\n",
    "                unlabel_i = dataset_set[I].x\n",
    "\n",
    "                counterpart = Tensor().type_as(unlabel)\n",
    "                \n",
    "                # '''debugging'''\n",
    "                # testing = True\n",
    "                # print(threshold_X.shape) \n",
    "                # for i in range(60): \n",
    "                #     for j in range(i, 61): \n",
    "                #         if torch.equal(threshold_X[i] ,threshold_X[j]): \n",
    "                #             testing = False\n",
    "                \n",
    "                # print(testing)\n",
    "                # break\n",
    "\n",
    "                for i in range(unlabel.shape[0]): \n",
    "                    check = True\n",
    "                    for j in range(unlabel_i.shape[0]): \n",
    "                       if torch.equal(unlabel[i], unlabel_i[j]):\n",
    "                           check = False\n",
    "                           break\n",
    "                    if check:\n",
    "                       counterpart = torch.cat((counterpart, unlabel[i].unsqueeze(0)))\n",
    "\n",
    "\n",
    "                # generate label of data in U\\U[i] by teacher_model classifier \n",
    "                y_counterpart = Tensor().type_as(unlabel)\n",
    "                for x in counterpart: \n",
    "                    y_counterpart = torch.cat((y_counterpart, teacher_model(x.unsqueeze(0)).unsqueeze(0)))\n",
    "\n",
    "                X_data = torch.cat((self.X_sup, unlabel_i, counterpart))\n",
    "                y_data = torch.cat((self.y_sup, dataset_set[I].y ,y_counterpart)).to(dtype=torch.int)\n",
    "                dl = CreateDataLoader(X_data, y_data, config.BATCH_SIZE, train_tfm, config.DEVICE)\n",
    "               \n",
    "                model.fit(config.EPOCHS, config.LEARNING_RATE, dl, test_dl, opt_func=optim.Adam, save_best=False)\n",
    "                if self.CalDisagreement(student_model.classify, model, unlabeled_dataset) > max: \n",
    "                    max = self.CalDisagreement(student_model, model, unlabeled_dataset)\n",
    "                    best = dataset_set[I]\n",
    "            \n",
    "            labeled_dataset.x = torch.cat((labeled_dataset.x, best.x))\n",
    "            labeled_dataset.y = torch.cat((labeled_dataset.y, best.y))\n",
    "            # remove sample from best dataset from unlabled dataset \n",
    "            for i in range(self.X_unsup.shape[0]): \n",
    "                check = True\n",
    "                for j in range(best.x.shape[0]): \n",
    "                    if torch.equal(self.X_unsup[i], best.x[j]):\n",
    "                        check = False\n",
    "                        break\n",
    "                    if not check:\n",
    "                        self.X_unsup = torch.cat((self.X_unsup[:i], self.X_unsup[:i+1]))\n",
    "                        unlabeled_dataset.y = torch.cat((unlabeled_dataset.y[:i], unlabeled_dataset.y[:i+1]))\n",
    "            # reassign teacher model \n",
    "            teacher_model = student_model\n",
    "        # return best model \n",
    "        self.model = teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selftraining = SelfTraining(GANSSL, X_sup, y_sup.to(dtype = torch.uint8), X_full, X_unsup, test_dl, transform=train_tfm, num_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "loss: 0.05876884236931801\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startacy: 0.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4994/59900 [00:14<02:41, 340.37it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA driver error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dl \u001b[38;5;241m=\u001b[39m \u001b[43mselftraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselfTraining\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRMSprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 69\u001b[0m, in \u001b[0;36mSelfTraining.selfTraining\u001b[0;34m(self, epochs, lr, batch_size, batch_per_epoch, sample_fraction, n, opt_func, sched, PATH, save_best, device)\u001b[0m\n\u001b[1;32m     65\u001b[0m confidence \u001b[38;5;241m=\u001b[39m Tensor()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m unsup_imgs \u001b[38;5;129;01min\u001b[39;00m tqdm(unsup_dl):\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# for i in tqdm(range(0, len(unsup_ds), batch_size)):  \u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# unsup_img = unsup_ds[i:min(len(unsup_ds), i+batch_size)]\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     prob \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43mstudent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munsup_imgs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# add 0.1 into label in order to prevent collapsing at label 0\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     labels \u001b[38;5;241m=\u001b[39m Tensor([\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m2.1\u001b[39m, \u001b[38;5;241m3.1\u001b[39m, \u001b[38;5;241m4.1\u001b[39m, \u001b[38;5;241m5.1\u001b[39m, \u001b[38;5;241m5.1\u001b[39m, \u001b[38;5;241m7.1\u001b[39m, \u001b[38;5;241m8.1\u001b[39m, \u001b[38;5;241m9.1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Tensor):\n\u001b[1;32m     10\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mConv(X)\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA driver error: out of memory"
     ]
    }
   ],
   "source": [
    "dl = selftraining.selfTraining(1, 1e-5, 64, 50, 0.1, 3, opt_func=optim.RMSprop, device=config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = torch.cuda.memory_summary(device=None, abbreviated=True)\n",
    "with open('check.txt', 'w') as f: \n",
    "    f.write(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
